{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488e3976-0958-4022-9d8f-2e0de2c38b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d016323-c987-44e6-b978-160c60e7a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('salary_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1694c119-f458-4e2e-ae03-67697dc216bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age   experience         salary\n",
      "count  7392.000000  7392.000000    7392.000000\n",
      "mean     33.624442     7.726444  111600.452279\n",
      "std       7.248476     5.947425   56104.726040\n",
      "min      21.000000     0.000000   20000.000000\n",
      "25%      28.000000     3.000000   60000.000000\n",
      "50%      33.000000     6.000000  110000.000000\n",
      "75%      37.000000    11.000000  160000.000000\n",
      "max      62.000000    34.000000  300000.000000\n"
     ]
    }
   ],
   "source": [
    "# 1. Handle missing values\n",
    "# Step 1: Identify Outliers using the IQR Method\n",
    "\n",
    "Q1 = df['salary'].quantile(0.25)\n",
    "Q3 = df['salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier thresholds (1.5 * IQR is a common threshold for detecting outliers)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Step 2: Remove rows with salary values outside the IQR bounds (outliers)\n",
    "df = df[(df['salary'] >= lower_bound) & (df['salary'] <= upper_bound)]\n",
    "\n",
    "# Impute numeric columns with the mean\n",
    "numeric_cols = ['age', 'experience', 'salary']\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Impute categorical columns with the most frequent value\n",
    "categorical_cols = ['sex', 'education', 'designation']\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607e940-13ab-4b61-aa85-eb9fc8093565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. One-Hot Encoding for categorical variables\n",
    "# We use OneHotEncoder to create binary columns for categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)  # drop='first' avoids multicollinearity\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(df[categorical_cols]), \n",
    "                            columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "df = df.drop(categorical_cols, axis=1)\n",
    "df = pd.concat([df, encoded_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1fa17-00c7-42e3-8974-7de7ebcc8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scaling numeric columns (Standardization)\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afb90c26-64b0-487b-833b-fefdd3c87103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age   experience         salary\n",
      "count  7392.000000  7392.000000    7392.000000\n",
      "mean     33.624442     7.726444  111600.452279\n",
      "std       7.248476     5.947425   56104.726040\n",
      "min      21.000000     0.000000   20000.000000\n",
      "25%      28.000000     3.000000   60000.000000\n",
      "50%      33.000000     6.000000  110000.000000\n",
      "75%      37.000000    11.000000  160000.000000\n",
      "max      62.000000    34.000000  300000.000000\n"
     ]
    }
   ],
   "source": [
    "# Inspect the preprocessed data\n",
    "df = df[df['salary'] > 10000]\n",
    "print(df.describe())\n",
    "df.to_csv(\"preprocessed_salary_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37f1cf82-101d-4c21-810d-3603a67d1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Splitting the Dataset\n",
    "\n",
    "# # Define X (features) and y (target)\n",
    "# X = df.drop('salary', axis=1)  # Features: all columns except salary\n",
    "# y = df['salary']  # Target: salary\n",
    "\n",
    "# # Split the data into training and testing sets (80-20 split)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Check the shapes to ensure the split is correct\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99306a20-23d9-4053-8eb5-edc2e0f5ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Linear Regression Model\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # 1. Initialize the Linear Regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# # 2. Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # 3. Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 4. Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "# print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a161380-7769-417f-9768-445ee5188cb5",
   "metadata": {},
   "source": [
    "# # Step 4: Model Tuning and Evaluation\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# # Initialize the Random Forest model\n",
    "# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "# r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# print(f\"Random Forest Mean Squared Error: {mse_rf}\")\n",
    "# print(f\"Random Forest R-squared: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ac1e9-1533-4ced-8537-118855b09031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
